{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1d0ded30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1a5f36e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94975d45",
   "metadata": {},
   "source": [
    "# Resize train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9991f28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 28x28 사이즈로 바꾸어 저장\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95b2def",
   "metadata": {},
   "source": [
    "# Load train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f9a5a343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=300):\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b194284",
   "metadata": {},
   "source": [
    "# Check first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c2f37ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacd849c",
   "metadata": {},
   "source": [
    "# Make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e5239610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 26, 26, 30)        840       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 13, 13, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 11, 11, 50)        13550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1250)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 50)                62550     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 77,093\n",
      "Trainable params: 77,093\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(30, (3,3), activation='relu', input_shape=(28,28,3)))    #컬러이미지므로 r,g,b=3\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(50, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))    #0~2까지 총 3개의 클래스를 구분\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7808d69f",
   "metadata": {},
   "source": [
    "# Teaching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "eae20461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.3761 - accuracy: 0.3000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 7.3779 - accuracy: 0.3467\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.8153 - accuracy: 0.4667\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.2253 - accuracy: 0.6200\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - accuracy: 0.7300\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3624 - accuracy: 0.8567\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1698 - accuracy: 0.9500\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0930 - accuracy: 0.9733\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9833\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f848c7ae790>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa73bde",
   "metadata": {},
   "source": [
    "# Resize test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "733aaf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "rock resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "scissor resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "paper resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "test_image_dir = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(test_image_dir)\n",
    "\n",
    "print(\"rock resize 완료!\")\n",
    "\n",
    "test_image_dir = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(test_image_dir)\n",
    "\n",
    "print(\"scissor resize 완료!\")\n",
    "\n",
    "test_image_dir = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(test_image_dir)\n",
    "\n",
    "print(\"paper resize 완료!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd5d41d",
   "metadata": {},
   "source": [
    "# Load test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4f946cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시험데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "def load_test_data(img_path, number_of_data=300):\n",
    "    img_size=28\n",
    "    color=3\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "\n",
    "    print(\"시험데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "test_image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_test_data(test_image_dir_path)\n",
    "x_test_norm = x_test/255.0\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd3eb3a",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "04d2de35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 1.3201 - accuracy: 0.7167\n",
      "test_loss: 1.320128321647644 \n",
      "test_accuracy: 0.7166666388511658\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1da5c65",
   "metadata": {},
   "source": [
    "# 회고\n",
    "처음에 ‘테스트 데이터는 \"앞으로 분류해야 하는 데이터\"이므로, 인덱스를 비워두어야 한다’라고 생각해서 테스트 데이터에 label(0~2)을 지정하는 코드를 적지 않았는데, 알고 보니 테스트 데이터에서 label은 “정답”을 입력하는 것이었다.\n",
    "그렇게 테스트 데이터에 입력한 정답 label과 학습시킨 딥러닝 모델이 분류한 label을 대조해 정확도를 판단하는 게 지금 작성한 코드의 메커니즘이라고 같은 조원인 혜지님이 친절하게 알려주셨다. 덕분에 코드도 고치고 이해도 확실히 했다.\n",
    "\n",
    "그렇게 한고비를 넘어 코드를 전부 작성은 했는데, 이번에는 요구하는 정확도가 도저히 나오지 않아 문제였다.\n",
    "여러 조원분에게 여쭤보니 resize할 때 크기를 28보다 크게 조정하기, keras.layers.Conv2D() 안의 값과 Dense() 안의 값, epoch 값을 크게 조정하기 등의 파훼법이 오갔는데, 퍼실님께서 \"정확도 문제는 사진 자체에 문제가 있을 확률이 높다\"라고 하셔서 조금 귀찮지만 사진을 새로 찍어 업로드하기로 마음먹었다.\n",
    "사진 300장을 다시 찍어서 올리는 일이 은근 번거롭다고 생각했는데, 다음날 쉬는 시간에 조원들과 이야기를 나누어보니 가위, 바위, 보 각각 600장씩 1800장을 찍어 올린 분도 계셨다. 투지가 정말 대단하다고 생각했다.\n",
    "\n",
    "각설하고, 사진을 교체했더니 0.3 정도 나오던 accuracy가 0.5 정도로 높아졌지만 여전히 0.6은 넘기지 못했다. 그래서 Conv2D의 값, Dense의 값, epoch 값의 숫자를 조금씩 조금씩 올려보았더니 드디어 0.6을 넘겼다. 그런데 어떤 때는 0.6을 웃돌아 0.85가 나오더니 언제는 밑돌아 0.51이 나오고, 또 언제는 0.69가 나오고 accuracy가 널뛰었다. 대략 10번중에 한두번은 0.4에서 0.5정도의 값이 자꾸 나와서 다른 조원들도 이런가 살펴보니 \"그래서 (accuracy 0.6이 넘는 순간 테스트를)멈춰야해요...\"라는 답변이 돌아왔다. 무엇이 accuracy 값의 진폭을 이렇게 만드는지 답답하다. 아마 돌고 돌아 결국은 사진의 문제가 아닐까 추측한다.\n",
    "\n",
    "수학부터 코딩까지, 바닥부터 배워야 할 것이 많아 일단은 더 수정않고 넘기지만 나중에라도 명확한 해답을 얻었으면 좋겠다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
