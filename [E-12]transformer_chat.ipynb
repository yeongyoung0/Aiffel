{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d1e9c11",
   "metadata": {},
   "source": [
    "# 필요한 패키지 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b75bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d135736",
   "metadata": {},
   "source": [
    "# 데이터 수집하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2d95e0",
   "metadata": {},
   "source": [
    "송영숙님이 공개한 챗봇 데이터 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e41a8600",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_chatbotdata = os.getenv('HOME') +'/aiffel/transformer_chatbot/data/ChatbotData .csv'\n",
    "df = pd.read_csv(path_chatbotdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a7c32c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q        0\n",
      "A        0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum()) # 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdca307c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1fdab18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail() # 데이터 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e2a947",
   "metadata": {},
   "source": [
    "# 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8384f77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11823\n"
     ]
    }
   ],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "MAX_SAMPLES = df.shape[0]\n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eabce55",
   "metadata": {},
   "source": [
    "### 전처리 함수 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434ff419",
   "metadata": {},
   "source": [
    "정규표현식을 사용하여 구두점을 제거해, 단어를 토크나이징 하는 일에 방해되지 않도록 정제하는 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ed13c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    \n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    \n",
    "    # (ㄱ~ㅎ, ㅏ~ㅣ,가~힣, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "    sentence = re.sub(r\"[^ ㄱ-ㅣ가-힣!,.?]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2727c19",
   "metadata": {},
   "source": [
    "본문의 로드데이터 함수가 고쳐도 고쳐도 오류가 나길래, 그냥 구글링을 통해 직접 코드를 입력해 questions와 answers에 저장해주었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcd8b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['p_Q'] = df['Q'].map(lambda x : preprocess_sentence(x))\n",
    "df['p_A'] = df['A'].map(lambda x : preprocess_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3659d764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n",
      "전처리 후의 22번째 질문 샘플: 가스비 장난 아님\n",
      "전처리 후의 22번째 답변 샘플: 다음 달에는 더 절약해봐요 .\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n",
    "#questions, answers = load_conversations()\n",
    "print('전체 샘플 수 :', len(df['p_Q']))\n",
    "print('전체 샘플 수 :', len(df['p_A']))\n",
    "print('전처리 후의 22번째 질문 샘플: {}'.format(df['p_Q'][21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(df['p_A'][21]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c39cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df['p_Q']\n",
    "answers = df['p_A']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dadaa6c",
   "metadata": {},
   "source": [
    "### 로드한 데이터 샘플 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2820b021",
   "metadata": {},
   "source": [
    "구두점들이 단어들과 분리되어 단어와 구두점 사이에는 공백이 추가된 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba4ed0e",
   "metadata": {},
   "source": [
    "# SubwordTextEncoder 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b59368",
   "metadata": {},
   "source": [
    "단어보다 더 작은 단위인 subword를 기준으로 토크나이징하고 각 토큰을 고유한 정수로 인코딩   \n",
    "각 문장을 토큰화하고 START_TOKEN 및 END_TOKEN 추가   \n",
    "MAX_LENGTH를 넘는 문장은 필터링   \n",
    "MAX_LENGTH보다 짧은 문장은 MAX_LENGTH 길이에 맞게 패딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76421ccd",
   "metadata": {},
   "source": [
    "### 단어장 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d1b80ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing...\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "print('processing...')\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성. (Tensorflow 2.3.0 이상) (클라우드는 2.4 입니다)\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93e6552f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aea0dbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8329]\n",
      "END_TOKEN의 번호 : [8330]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44cfebe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8331\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ff0383",
   "metadata": {},
   "source": [
    "### 각 단어를 고유한 정수로 인코딩 & 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a52e182a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5819, 609, 2499, 4169]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2686, 7646, 8, 6357, 96, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c9f60da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 20\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc0de52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "        # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "  \n",
    "    # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "    return tokenized_inputs, tokenized_outputs\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df79c4d4",
   "metadata": {},
   "source": [
    "길이가 20을 넘는 경우를 필터링 했으므로, 단어장 크기와 샘플의 개수를 다시 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85e0d344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8331\n",
      "필터링 후의 질문 샘플 개수: 11791\n",
      "필터링 후의 답변 샘플 개수: 11791\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a4deeb",
   "metadata": {},
   "source": [
    "### 교사 강요 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f376da",
   "metadata": {},
   "source": [
    "자기회귀 모델에서 교사 강요를 하지 않은 경우, 잘못된 예측이 다음 시점의 입력으로 들어가면서 연쇄적으로 예측 정확도에 영향을 미친다. 이는 훈련 과정에서 훈련 속도가 지나치게 느려지는 결과를 초래하므로 (자기회귀 모델인)트랜스포머 디코더에 쿄사 강요를 적용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b069413f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5207a8",
   "metadata": {},
   "source": [
    "# 모델 구성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec10425",
   "metadata": {},
   "source": [
    "### 포지셔널 인코딩 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9481bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20c41494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_pos_encoding = PositionalEncoding(50, 512)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94940843",
   "metadata": {},
   "source": [
    "### 스케일드 닷 프로덕트 어텐션 함수 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991f6595",
   "metadata": {},
   "source": [
    "어텐션은 안어들 간의 유사도를 구하는 메커니즘   \n",
    "1.어텐션 함수는 주어진 쿼리(auery)에 대해서 모든 키(key)와의 유사도를 각각 구한다.   \n",
    "2.구해낸 유사도를 키와 맵핑된 값(value)에 반영한다.   \n",
    "3.유사도가 반영된 값을 모두 더해서 뭉치면 이를 최정 결과인 어텐션 값(Attention Value)라고 한다.   \n",
    "   \n",
    "1.Q, K, V는 단어벡터를 행으로 하는 문장 행렬   \n",
    "2.벡터의 내적(dot product)은 벡터의 유사도를 의미   \n",
    "3.특정 값을 분모로 사용하는 것은 값의 크기를 조절하는 스케일링을 위함   \n",
    "   \n",
    "내적을 통해 벡터 간 유사도를 구한 후에 특정 값을 분모로 나눠주는 방식으로, Q와 K의 유사도를 구하였다고 하여 스케일드 닷 프로덕트 어텐션이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddebedf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # 가중치를 정규화\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 패딩에 마스크 추가\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax적용\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output\n",
    "\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cdf7f4",
   "metadata": {},
   "source": [
    "### 멀티 헤드 어텐션 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "537796cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "            query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "            batch_size = tf.shape(query)[0]\n",
    "\n",
    "            # Q, K, V에 각각 Dense를 적용합니다\n",
    "            query = self.query_dense(query)\n",
    "            key = self.key_dense(key)\n",
    "            value = self.value_dense(value)\n",
    "\n",
    "            # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "            query = self.split_heads(query, batch_size)\n",
    "            key = self.split_heads(key, batch_size)\n",
    "            value = self.split_heads(value, batch_size)\n",
    "\n",
    "            # 스케일드 닷 프로덕트 어텐션 함수\n",
    "            scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "            scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "           \n",
    "            # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "            concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "            # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "            outputs = self.dense(concat_attention)\n",
    "\n",
    "            return outputs\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1477b4b8",
   "metadata": {},
   "source": [
    "### 패딩 마스킹(Padding Masking) 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7929edc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f68439",
   "metadata": {},
   "source": [
    "### 룩 어헤드 마스킹(Look-ahead Masking) 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "457f4792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acda2102",
   "metadata": {},
   "source": [
    "### 트랜스포머의 인코더 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3dd4c3",
   "metadata": {},
   "source": [
    "하나의 인코더 층은 크게 총 2개의 sublayer로 나누어진다.   \n",
    "셀프 어텐션(멀티 헤드 어텐션으로, 병렬적)   \n",
    "피드 포워드 신경망   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0d907f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5d3e32",
   "metadata": {},
   "source": [
    "### 인코더 층을 쌓아 인코더 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b481eb32",
   "metadata": {},
   "source": [
    "구현한 인코더 층에 Embedding layer와 Positional Encoding을 연결하고, 사용자가 원하는 만큼 인코더 층을 쌓음으로써 트랜스포머의 인코더가 완성된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15b70afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "      )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c17c5e",
   "metadata": {},
   "source": [
    "### 트랜스포머의 디코더 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b85f6a0",
   "metadata": {},
   "source": [
    "디코더는 세 개의 sublayer로 구성된다.   \n",
    "셀프 어텐션   \n",
    "인코더-디코더 어텐션(셀프 어텐션과 달리 Query가 디코더의 벡터인 반면 Key와 Value가 인코더의 벡터다)   \n",
    "피드 포워드 신경망   \n",
    "디코더의 셀프 어텐션, 인코더-디코더 어텐션 두 개의 어텐션 모두 스케일드 닷 프로덕트 어텐션을 멀티헤드 어텐션으로 병렬 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cae898d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': look_ahead_mask\n",
    "        })\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1,\n",
    "            'key': enc_outputs,\n",
    "            'value': enc_outputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245bd7c3",
   "metadata": {},
   "source": [
    "### 디코더 층을 쌓아 디코더 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6270a1",
   "metadata": {},
   "source": [
    "구현한 디코더 층에 Embedding layer와 Positional Encoding을 연결하고, 사용자가 원하는 만큼 디코더 층을 쌓아 트랜스포머의 디코더가 완성된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0df0cded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "      )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33970136",
   "metadata": {},
   "source": [
    "함수로 구현한 인코더 층과 디코더 층을 하나로 조합하여 트랜스포머 모델을 만들 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a19141",
   "metadata": {},
   "source": [
    "### 모델 정의 및 학습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8926e58",
   "metadata": {},
   "source": [
    "인코더 층 함수와 디코더 층 함수를 사용해 트랜스포머 함수를 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6cbebce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e9b96d",
   "metadata": {},
   "source": [
    "### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a07e311c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3186944     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3714304     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8331)   2141067     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,042,315\n",
      "Trainable params: 9,042,315\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cae566",
   "metadata": {},
   "source": [
    "### 손실 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726f73de",
   "metadata": {},
   "source": [
    "레이블인 시퀀스에 패딩이 되어 있으므로, loss 계산 시 패딩 마스크를 적용해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1dddf7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd56aea",
   "metadata": {},
   "source": [
    "### 커스텀된 학습률"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8642a1ca",
   "metadata": {},
   "source": [
    "모델학습 초기에 learning rate를 급격히 높였다가, train step이 진행됨에 따라 서서히 낮추어 가면서 안정적으로 수렴하게 하는 커스텀 학습률 스케줄링(Custom Learning rate Scheduling) 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "965904c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f56d085",
   "metadata": {},
   "source": [
    "### 모델 컴파일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594e1ffb",
   "metadata": {},
   "source": [
    "손실 함수와 커스텀된 학습률을 사용하여 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30c8d193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47153b6",
   "metadata": {},
   "source": [
    "### 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da85d3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "185/185 [==============================] - 13s 38ms/step - loss: 2.9787 - accuracy: 0.0661\n",
      "Epoch 2/20\n",
      "185/185 [==============================] - 7s 37ms/step - loss: 2.4201 - accuracy: 0.1016\n",
      "Epoch 3/20\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 2.0538 - accuracy: 0.1036\n",
      "Epoch 4/20\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 1.8956 - accuracy: 0.1110\n",
      "Epoch 5/20\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 1.7769 - accuracy: 0.1180\n",
      "Epoch 6/20\n",
      "185/185 [==============================] - 7s 37ms/step - loss: 1.6553 - accuracy: 0.1265\n",
      "Epoch 7/20\n",
      "185/185 [==============================] - 7s 37ms/step - loss: 1.5206 - accuracy: 0.1382\n",
      "Epoch 8/20\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 1.3727 - accuracy: 0.1545\n",
      "Epoch 9/20\n",
      "185/185 [==============================] - 7s 37ms/step - loss: 1.2121 - accuracy: 0.1720\n",
      "Epoch 10/20\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 1.0462 - accuracy: 0.1915\n",
      "Epoch 11/20\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.8789 - accuracy: 0.2120\n",
      "Epoch 12/20\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.7160 - accuracy: 0.2339\n",
      "Epoch 13/20\n",
      "185/185 [==============================] - 7s 37ms/step - loss: 0.5630 - accuracy: 0.2558\n",
      "Epoch 14/20\n",
      "185/185 [==============================] - 7s 37ms/step - loss: 0.4306 - accuracy: 0.2761\n",
      "Epoch 15/20\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.3186 - accuracy: 0.2952\n",
      "Epoch 16/20\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.2313 - accuracy: 0.3115\n",
      "Epoch 17/20\n",
      "185/185 [==============================] - 7s 37ms/step - loss: 0.1679 - accuracy: 0.3229\n",
      "Epoch 18/20\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.1297 - accuracy: 0.3300\n",
      "Epoch 19/20\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.1075 - accuracy: 0.3335\n",
      "Epoch 20/20\n",
      "185/185 [==============================] - 7s 38ms/step - loss: 0.0962 - accuracy: 0.3354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9698435c10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7a8af1",
   "metadata": {},
   "source": [
    "# 모델 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebf47ad",
   "metadata": {},
   "source": [
    "### decoder_inference()함수 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d0922c",
   "metadata": {},
   "source": [
    "1.새로운 입력 문장에 대해 훈련 때와 동일한 전처리   \n",
    "2.입력 문장을 토크나이징, START_TOKEN과 END_TOKEN으르 추가   \n",
    "3.패딩 마스킹과 룩 어헤드 마스킹 계산   \n",
    "4.디코더는 입력 시퀀스로부터 다음 단어 예측   \n",
    "5.디코더는 예측된 다음 단어를 기존의 입력 시퀀스에 추가하여 새로운 입력으로 사용   \n",
    "6.END_TOKEN이 예측되거나 문장 최대 길이에 도달하면 디코더 동작 중지   \n",
    "의 과정을 담은 decoder_inference() 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eea10419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "    # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "    sentence = tf.expand_dims(\n",
    "        START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "    # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "        # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "        # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22070cc0",
   "metadata": {},
   "source": [
    "### sentence_generation()함수 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b9f2f7",
   "metadata": {},
   "source": [
    "임의의 입력 문장에 대해 decoder_inference()함수를 호출, 챗봇의 대답을 얻는 sentence_generation()함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0513c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "def sentence_generation(sentence):\n",
    "    # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print('입력 : {}'.format(sentence))\n",
    "    print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f876ef72",
   "metadata": {},
   "source": [
    "# 챗봇 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df847089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 이름이 뭐야?\n",
      "출력 : 위로봇이요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'위로봇이요 .'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"이름이 뭐야?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae2f5934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 지금 너무 졸려\n",
      "출력 : 낮잠은  분만 자세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'낮잠은  분만 자세요 .'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"지금 너무 졸려\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43075fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 사랑은 뭘까?\n",
      "출력 : 사랑은 한 없이 줘도 아깝지 않은거라고 생각해요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'사랑은 한 없이 줘도 아깝지 않은거라고 생각해요 .'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"사랑은 뭘까?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8de2d36",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73c5d1a",
   "metadata": {},
   "source": [
    "이번 Exploration은 지난 화요일 결석을 했고, 지금까지 쳐다보지도 않았기 때문에 그야말로 “단단히 밀린 과제”였다.   \n",
    "참고로 나에게 세상에서 하기 싫은 일 top2중 1위는 했던 일 세이브파일 날려서 또 하기, 2위는 밀린 일 하기이므로 이번 과제를 시작하기까지 정말 오랜 시간이 걸렸다.   \n",
    "즉, 디지몬 극장판 3편을 보고 나서야 겨우 의자에 앉았다. 1999년, 당시 초등학교 4학년인데도 각종 코드를 구현해 디지털 세계를 구한 한솔이를 존경하는 마음으로…   \n",
    "자리에 앉은 다음에도 너무 너무 너무 하기가 싫어서 마음으로 엉엉 울며 노드를 시작했는데, 생각외로 너무 너무 너무 재미있고 이해가 금방 돼서 시간 가는 줄 모르고 본문을 노션에 정리하고 코드를 옮겨 적었다.   \n",
    "로드 데이터 함수가 어떻게 해도 오류가 나길래 그냥 직접 question과 answer 데이터를 집어넣은 것 빼곤 별 오류 없이 아주 수월하게 진행했고, 결과적으로 만족스러운 대답을 도출하는 챗봇이 만들어졌다.   \n",
    "사실 재미있어서 이것 저것 코드를 더 만져볼까 했는데, 이미 괜찮은 결과를 얻고 나니 괜히 건드렸다가 돌이킬 수 없는 강을 건너는거 아닌가 싶어 제출 후에 해보려고 한다.   \n",
    "RNN과 LSTM cs231n강의 풀잎 이후 이 노드를 보게 된 것이 순서상 많은 도움이 됐다. 결국 트랜스포머란 RNN의 진화형이기 때문에, 딱 어제 RNN을 공부하고 보니 빠른 1회독만으로 이해가 꽤 수월했다.   \n",
    "이젠 전처리도 나름 익숙해져서 결측치 확인 등 본문에 없던 자잘한 부분도 괜히 추가해봤다.   \n",
    "학습에 있어 그 기반에는 즐거움이 있어야겠구나 다시금 느낀 과제였다. 앞으로는 너무 너무 너무 하기 싫을 땐 초등학생 신분으로 디지털 세계를 구한 선택받은 아이들을 생각하며 정신 차리고, 언젠가 디지털 월드에 난파되었을 때를 대비해야 한다는 마음으로 몰입해야지. 막상 들여다봤더니 재미있더라~ 하는 이 경험 또한 두고두고 상기해야겠다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
